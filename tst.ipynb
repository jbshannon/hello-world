{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EC486 LT Problem Set 9\n",
    "\n",
    "Edited by Jack Shannon\n",
    "\n",
    "Based on [Jin, Ginger Zhe, and Phillip Leslie. “Reputational Incentives for Restaurant Hygiene.” American Economic Journal: Microeconomics 1, no. 1 (2009): 237–67.\n",
    "](www.jstor.org/stable/25760354)\n",
    "\n",
    "This document was produced with [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/) running [`stata_kernel`](https://kylebarron.dev/stata_kernel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "> What is the question and the goal of the paper?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The authors begin by asking:\n",
    "\n",
    "> When do reputations provide effective incentives for firms to maintain high unobservable effort, and when should we invoke government intervention based on a failure of the market to provide adequate information?\n",
    "\n",
    "After noting a government intervention (the introduction of hygiene scorecards to be prominently displayed) that reduced hospitalizations from food-borne illness by 20%, they introduce the goal of this paper:\n",
    "\n",
    "> In this study, we ask whether reputational incentives caused at least some restaurants to provide good hygiene.\n",
    "\n",
    "They pursue this question with two smaller questions:\n",
    "\n",
    "1. Chain effects?\n",
    "    - Chain-affiliated restaurants may share the reputation of the chain as a whole\n",
    "    - Test the hypothesis that chain restaurants tend to face stronger reputational incentives than independent restaurants\n",
    "    - Evidence of franchisees exerting less effort to maintain good hygiene would provide verification that chain affiliation is a source of reputational incentives.\n",
    "2. Regional variation\n",
    "    - All else equal, two restaurants located beside each other face similar consumer learning\n",
    "    - Implies geographic clustering in the magnitude of restaurants' information differences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "> What is the theoretical foundation upon which the empirical model is based?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Effects\n",
    "\n",
    "In order to test whether there are different reputational incentives between chain restaurants and non-chain restaurants – and between company-owned chains and franchised chains - the authors develop a model of the effects of a change in consumer learning about product quality (i.e. hygiene)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplest Model\n",
    "\n",
    "The simple underlying model has the following characteristics:\n",
    "\n",
    "- Hygiene (quality) is costly to produce\n",
    "- Hygiene is imperfectly observed by consumers\n",
    "    - Scorecard intervention improves consumer learning\n",
    "    - Chain restaurants have different learning effects than non-chain restaurants\n",
    "\n",
    "This in turn implies:\n",
    "\n",
    "- Pre-intervention\n",
    "    - Chains produce higher quality than non-chains\n",
    "        - Due to differences in consumer learning\n",
    "    - Company-owned chains produce higher quality than franchised chains\n",
    "        - Due to externality of learning on other branches in the chain\n",
    "        - Company-owned restaurants internalize this, franchises do not\n",
    "    - Represented by ranked marginal revenue curves:\n",
    "    $${MR}^b_{nc}(h) < {MR}^b_{cf}(h) < {MR}^b_c(h)$$\n",
    "    for any level of hygiene quality $h$\n",
    "        - $b$ – before intervention\n",
    "        - $nc$ – non-chain restaurant\n",
    "        - $cf$ – franchised chain restaurant\n",
    "        - $c$ - company-owned chain restaurant\n",
    "    - NB: this marginal revenue is the change in profit for a marginal increase in *hygiene*, not food output\n",
    "- Post-intervention\n",
    "    - Consumer learning is equalized across chains and non-chains\n",
    "    - All firms then face the same marginal revenue curve\n",
    "    $${MR}^a(h) > {MR}^b(h)$$\n",
    "    for any level of hygiene quality $h$ and any pre-intervention marginal revenue ${MR}^b$\n",
    "\n",
    "Assuming that all firms face the same marginal cost curve, we expect to see the following ranking of equilibrium hygiene levels:\n",
    "$$h^b_{nc} < h^b_{cf} < h^b_c < h^a$$\n",
    "\n",
    "This is illustrated in Figure 1 from the paper:\n",
    "![Figure 1](./images/figure1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost Heterogeneity\n",
    "\n",
    "What if chains and non-chains not only face different reputational incentives, but also different cost curves? Suppose that it is less costly (in terms of effort) for chains to produce hygiene quality than non-chains. What will be the effect of the change in consumer learning?\n",
    "\n",
    "##### Parallel Shift\n",
    "\n",
    "Suppose that the marginal cost curves are parallel, e.g. ${MC}_c(h) = {MC}_{nc}(h) - \\gamma$ for some $\\gamma > 0$. Because all curves are linear, the change in hygiene levels due to cost differences is just a constant. In other words, the horizontal distance between the intersection of a marginal revenue curve with the two marginal cost curves is constant (call it $\\Delta$) for all marginal revenue curves. This means that if the difference in hygiene levels between chains and non-chains decreases after the intervention, then chains and non-chains must have had different marginal revenue curves pre-intervention. The reasoning can be summarized as:\n",
    "\n",
    "- Suppose $h^b_{nc} - h^b_c > h^a_{nc} - h^a_c$\n",
    "- ${MR}^a_{nc} = {MR}^a_c \\Rightarrow h^a_{nc} - h^a_c = \\Delta$\n",
    "- Then $h^b_{nc} - h^b_c > \\Delta$\n",
    "- Therefore ${MR}^b_{nc} \\neq {MR}^b_c$\n",
    "\n",
    "Since this difference in the marginal revenue curves is evidence of reputational incentives, any analysis that relies on the difference in hygiene level changes before and after the intervention is the same as in the basic model.\n",
    "\n",
    "As before, franchises and company-owned restaurants still face the same marginal cost curve, any pre-intervention differences in hygiene levels must come from a difference in marginal revenue curves, i.e. reputational incentives.\n",
    "\n",
    "All this can be seen in Figure 2 from the paper:\n",
    "![Figure 2](./images/figure2.png)\n",
    "\n",
    "##### Affine Transformation\n",
    "\n",
    "Suppose instead that chains face a marginal cost curve that is lower but steeper than the marginal cost of non-chains: ${MC}_c(h) = \\gamma_1 \\cdot {MC}_{nc}(h) - \\gamma_0$ with $\\gamma_0 > 0$ and $\\gamma_1 > 1$. Under this setting, even if both chains and non-chains faced the same marginal revenue curve pre-intervention, the difference in hygiene levels would shrink after the intervention because the two marginal cost curves would be closer together.\n",
    "\n",
    "To correct for this, the authors propose conditioning on the average post-intervention hygiene level. Their reasoning is as follows:\n",
    "\n",
    "- For two restaurants $1$ and $2$, suppose:\n",
    "    1. $h_1^a = h_2^a$\n",
    "    2. $h_1^b \\neq h_2^b$\n",
    "    3. MR curves do not cross, MC curves do not cross\n",
    "- 1 and 3 imply ${MC}_1^a = {MC}_2^a$\n",
    "- MC does not change with the intervention\n",
    "- Therefore ${MC}^b_1 = {MC}^b_2$\n",
    "- Then $h_1^b \\neq h_2^b$ implies ${MR}^b_1 \\neq {MR}^b_2$\n",
    "\n",
    "I don't buy this argument because conditioning on post-intervention scores shifts one MC curve onto another, so even if they do not cross in reality, they can cross if they are made to go through the same point. The reasoning is correct, but only for factual observations, not counterfactuals, which is what the conditioning amounts to.\n",
    "\n",
    "This is illustrated by Figure 3 in the paper:\n",
    "![Figure 3](./images/figure3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "> Describe the data being used.\n",
    "\n",
    "Data comes primarily from health inspections carried out in Los Angeles by the Department of Health Services (DHS). The variation to be exploited comes from the introduction of a grade card system for displaying sanitation scores. The grade card is to be prominently displayed and assign a letter grade based on sanitation inspection scores:\n",
    "\n",
    "| Score  | Card  |\n",
    "| :---:  | :---: |\n",
    "| 90-100 |   A   |\n",
    "| 80-89  |   B   |\n",
    "| 70-79  |   C   |\n",
    "| <70    | numeric score displayed |\n",
    "\n",
    "The timeline of events that led to the introduction of the grade cards was as follows:\n",
    "\n",
    "1. **17 November 1997** – Hidden-camera news investigation reveals unsanitary conditions in LA restaurants\n",
    "2. **17 December 1997** – County board of supervisors votes to implement grade card system\n",
    "3. **16 January 1998** - Inspectors begin issuing grade cards\n",
    "\n",
    "The data used is:\n",
    "\n",
    "- Department of Health Services (DHS) inspections\n",
    "    - hygiene scores\n",
    "    - restaurant characteristics\n",
    "- Name and address of each restaurant\n",
    "    - demographic data\n",
    "    - information on local businesses\n",
    "- Name and Yellow Pages\n",
    "    - cuisine type\n",
    "- Zagat Survey restaurant guide\n",
    "    - restaurants included\n",
    "    - associated review scores\n",
    "- Ownership information (from DHS)\n",
    "    - company-owned or franchise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "> Is the data sufficient to answer the question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data should be sufficient. It provides a way of identifying chains from non-chains and franchises from company-owned restaurants, which is the key heterogeneity needed to evaluate the hypothesis. To answer the question about the regional effects of learning, they have demographic and employment data for the region corresponding to each restaurant.\n",
    "\n",
    "The key assumption throughout paper is that the introduction of the inspection grade card system is exogenous, which the authors argue is plausible because its introduction was a) unexpected and b) rapid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "> Summarize the main results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Effects\n",
    "\n",
    "#### Basic Model\n",
    "\n",
    "The first regression looks at hygiene scores before the introduction of the grade card system and tests to see whether chains and franchises have on average different hygiene scores than non-chains:\n",
    "\n",
    "$$s^b_{ijt} = \n",
    "    \\alpha_j \n",
    "    + \\beta c_i\n",
    "    + \\gamma f_i\n",
    "    + \\delta_1 nchain_i\n",
    "    + \\delta_2 perchain_i\n",
    "    + X_i \\theta \n",
    "    + \\varepsilon_{ijt}$$\n",
    "    \n",
    "| Variable     | Description                                                                         |\n",
    "| :----------- | :---------------------------------------------------------------------------------- |\n",
    "| $s^b_{ijt}$  | pre-intervention inspection score of restaurant $i$ in region $j$ at inspection $t$ |\n",
    "| $\\alpha_j$   | region fixed effect                                                                 |\n",
    "| $c_i$        | indicator for chain restaurant                                                      |\n",
    "| $f_i$        | indicator for franchised unit                                                       |\n",
    "| $nchain_i$   | number of restaurants in LA belonging to the same chain as restaurant $i$           |\n",
    "| $per_i$ | percentage of US chain units located in LA                                          |\n",
    "| $X_i$        | observable characteristics of restaurant $i$                                        |\n",
    "\n",
    "The model predicts:\n",
    "- $\\beta > 0$ – chains have higher pre-intervention hygiene scores\n",
    "- $\\gamma <0$ - franchised units have lower pre-intervention hygiene scores than chains\n",
    "\n",
    "Note for the second point that the company-owned chain effect is $\\beta$ but the franchised effect is $\\beta + \\gamma$ and since we hypothesized that franchised units have lower marginal revenue curves than compnay-owned units, we expect $\\beta + \\gamma < \\beta$, or $\\gamma < 0$.\n",
    "\n",
    "The results of this regression are reported in the first column of Table 3 (included at the end of this heading).\n",
    "\n",
    "To control for unobserved restaurant-level heterogeneity, the authors run a second regression:\n",
    "\n",
    "$$s_{it} = \n",
    "    \\alpha_i\n",
    "    + \\beta_0 g_t\n",
    "    + \\beta g_t c_i\n",
    "    + \\gamma g_t f_i\n",
    "    + \\delta_1 g_t nhcain_i\n",
    "    + \\delta_2 g_t perchain_i\n",
    "    + \\varepsilon_{it}$$\n",
    "    \n",
    "| Variable     | Description                                                               |\n",
    "| ------------ | ------------------------------------------------------------------------- |\n",
    "| $s_{it}$     | inspection score of restaurant $i$ at inspection $t$                      |\n",
    "| $\\alpha_i$   | restaurant fixed effect                                                   |\n",
    "| $g_t$        | indicator for whether grade cards were in place at inspection $t$         |\n",
    "| $c_i$        | indicator for chain restaurant                                            |\n",
    "| $f_i$        | indicator for franchised unit                                             |\n",
    "| $nchain_i$   | number of restaurants in LA belonging to the same chain as restaurant $i$ |\n",
    "| $per_i$ | percentage of US chain units located in LA                                |\n",
    "\n",
    "The model predicts:\n",
    "- $\\beta < 0$ - the effect on inspection scores is smaller for chains than for non-chains\n",
    "- $\\gamma > 0$ - the effect on inspection scores is bigger for franchise units than for company-owned units\n",
    "\n",
    "They also re-estimate the model using only the subsample of restaurants with Zagat reviews and with a dummy for an A grade rather than a continuous inspection score. The results are reported in the second column of Table 3.\n",
    "\n",
    "#### Cost Heterogeneity\n",
    "\n",
    "To control for heterogeneity in marginal cost curves, the authors run the following regression that controls for the average post-intervention sanitation score $\\overline s_i^a$:\n",
    "\n",
    "$$s^b_{ijt} = \n",
    "    \\alpha_j\n",
    "    + \\beta c_i\n",
    "    + \\gamma f_i\n",
    "    + \\delta_1 nchain_i\n",
    "    + \\delta_2 perchain_i\n",
    "    + \\delta \\overline s_i^a\n",
    "    + X_i \\theta \n",
    "    + \\varepsilon_{ijt}$$\n",
    "    \n",
    "Since including $\\overline s_i^a$ theoretically puts restaurants on the same marginal cost curve, the interpretation of $\\beta$ and $\\gamma$ is as before, so the model still predicts $\\beta > 0$ and $\\gamma <0$. They run this regression with and without city fixed effects. The results are reported in columns 3 and 4 of Table 3.\n",
    "\n",
    "![Table 3](./images/table3.png)\n",
    "\n",
    "For all specifications, $\\beta$ has the correct sign and is significantly different from zero. Furthermore, $\\gamma$ has the correct sign in all specifications, and is significantly different from zero in all but column 4.\n",
    "\n",
    "| Specification | Coefficient |  Prediction  | Estimate | Standard Error | Significance Level |\n",
    "| :-----------: | :---------: | :----------: | -------: | :------------: | :----------------: |\n",
    "|       1       |   $\\beta$   | $\\beta  > 0$ |   3.7283 |     0.8761     |         1%         |\n",
    "|       1       |  $\\gamma$   | $\\gamma < 0$ |  -0.5722 |     0.2789     |         5%         |\n",
    "|       2       |   $\\beta$   | $\\beta  < 0$ |  -3.9350 |     0.5745     |         1%         |\n",
    "|       2       |  $\\gamma$   | $\\gamma > 0$ |   1.0948 |     0.3924     |         1%         |\n",
    "|       3       |   $\\beta$   | $\\beta  > 0$ |   4.6846 |     1.2806     |         1%         |\n",
    "|       3       |  $\\gamma$   | $\\gamma < 0$ |  -1.5693 |     0.4601     |         1%         |\n",
    "|       4       |   $\\beta$   | $\\beta  > 0$ |   2.7024 |     0.8806     |         1%         |\n",
    "|       4       |  $\\gamma$   | $\\gamma < 0$ |  -0.1556 |     0.2739     |        none        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regional Variation\n",
    "\n",
    "The model of regional variation has consumer information...\n",
    "\n",
    "1. $I_{ij} = I(c_i, g, r_j)$\n",
    "    - $I_{ij}$ - level of consumer information about restaurant $i$ in region $j$\n",
    "    - $c_i$ - indicator for being a chain\n",
    "    - $g$ - indicator for grade card system being in place\n",
    "    - $r_j$ - degree of repeat business in region $j$\n",
    "2. ${MR}(h_i, I(c_i, g, r_j), w_j)$\n",
    "    - $h_i$ - hygiene level of restaurant $i$\n",
    "    - $w_j$ - net value of all other local characteristics\n",
    "    - Note that region $j$ only affects MR through consumer information $I_{ij}$\n",
    "3. ${MC}(h_i, c_i, w_j)$\n",
    "4. $I(c_i, 1, r_j) = I(c_i,\\overline r)$\n",
    "    - $\\overline r$ - level of consumer learning from grade cards\n",
    "    - This is the assumption that the grade cards equalize consumer information\n",
    "5. $h^*(c_i, g, r_j, w_j, \\overline r)$ solves ${MR}={MC}$\n",
    "    - $h^*_{ij}(g=0) = \\underbrace{a_1 r_j + a_2 w_j + a_3 r_j w_j}_{\\alpha^b_j} + b_1 c_i$\n",
    "    - $h^*_{ij}(g=1) = \\underbrace{a_1 \\overline r + a_2 w_j + a_3 \\overline r w_j}_{\\alpha^a_j} + b_1 c_i$\n",
    "6. $H_0: r_j = r$\n",
    "    - Under $H_0$, can rearrange the equations defining $\\alpha^b_j$ and $\\alpha^a_j$ to get:\n",
    "    - $\\alpha^a_j = \\kappa_1 + \\kappa_2 \\alpha^b_j$\n",
    "\n",
    "The unrestricted model consists of two separate regrssions:\n",
    "\n",
    "1. $s^b_{ijt} = \\alpha^b_j + \\beta^b c_i + \\gamma^b f_i + X_i \\theta^b + \\varepsilon_{ijt}$\n",
    "2. $s^a_{ijt} = \\alpha^a_j + \\beta^a c_i + \\gamma^a f_i + X_i \\theta^a + \\varepsilon_{ijt}$\n",
    "\n",
    "They test the null hypothesis in two ways.\n",
    "\n",
    "First, they assume that $a_3 = 0$ (see the definition $h^*$). This implies that $\\alpha^a_j - \\alpha^b_j = a_1(\\overline r - r)$, which is constant across regions $j$. The test then becomes whether $\\alpha^a_j - \\alpha^b_j$ is constant across regions, using different definitions for regions.\n",
    "\n",
    "Second, they allow for $a_3 \\neq 0$ and use the fact that $r_j=r$ implies $\\alpha^a_j = \\kappa_1 + \\kappa_2 \\alpha^b_j$. The restricted model is the two regressions:\n",
    "\n",
    "1. $s^b_{ijt} = \\alpha^b_j + \\beta^b c_i + \\gamma^b f_i + X_i \\theta^b + \\varepsilon_{ijt}$\n",
    "2. $s^b_{ijt} = \\kappa_1 + \\kappa_2 \\alpha^b_j + \\beta^a c_i + \\gamma^a f_i + X_i \\theta^a + \\varepsilon_{ijt}$\n",
    "\n",
    "Note that this equation is nonlinear in parameters (because of the $\\kappa_2 \\alpha^b_j$ term), so it must be estimated using nonlinear least squares.\n",
    "\n",
    "The sum of squared residuals from this equation is the $RSS_r$ used for the F-statistic.\n",
    "\n",
    "The results are reported in Table 5:\n",
    "\n",
    "![Table 5](./images/table5.png)\n",
    "\n",
    "Note that all F-statistics lead to rejection of the null of no regional variation in consumer learning at the 99% level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "> On the course webpage, you can find the paper’s dataset `data-for-AEJ.dta`, and the file `readme-for-AEJ.txt` describes the variables. Attempt to replicate Table 2 and Table 3 (optional) of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "* Prepare Stata\n",
    "clear all\n",
    "cap log close _all\n",
    "set more off\n",
    "set linesize 80\n",
    "use input/data-for-AEJ, clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to replicate Table 2:\n",
    "\n",
    "![Table 2](./images/table2.png)\n",
    "\n",
    "From a theoretical perspective, this is straightforward. All we have to do is run the appropriate regressions and report the RSS and $R^2$. The complicated bit is slogging through the codebook to figure out which variables to include in each regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to Use\n",
    "\n",
    "> Table 2 presents variance decompositions in which observation is a restaurant inspection before the introduction of grade cards.\n",
    "\n",
    "Since we only use observations before the regulation, we can drop all the other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(43,321 observations deleted)\n",
      "\n",
      "\n",
      "file data/q6.dta saved\n"
     ]
    }
   ],
   "source": [
    "keep if reg_yes==0\n",
    "cap mkdir data\n",
    "save data/q6, replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant\n",
    "\n",
    "> Conditioning the observed scores on quarterly dummies and inspection regime dummies explains 4 percent of the score variation.\n",
    "\n",
    "Which variables contain dummies for quarters and inspection regimes? We've already conditioned on the inspection regime using `reg_yes`. The readme tells us `yyqq_*` contains year-quarterly dummies.\n",
    "\n",
    "According to the note in the table, all specifications use the dummies `yyqq_*`, so saying we're regressing on a constant here means we regress the inspection scores on the year-quarter dummies and a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note: yyqq_11 omitted because of collinearity\n",
      "note: yyqq_12 omitted because of collinearity\n",
      "note: yyqq_13 omitted because of collinearity\n",
      "note: yyqq_14 omitted because of collinearity\n",
      "\n",
      "Linear regression                               Number of obs     =     83,790\n",
      "                                                F(10, 83779)      =     538.92\n",
      "                                                Prob > F          =     0.0000\n",
      "                                                R-squared         =     0.0419\n",
      "                                                Root MSE          =     14.412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg score yyqq_*, robust notable // display header but not coefficient table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now my `e()` vector should contain all the information I need for the table. For a full list of everything included in `e()`, type `ereturn list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RSS = 17402286\n",
      "\n",
      "R^2 = .04191082\n",
      "\n",
      "df  = 10\n"
     ]
    }
   ],
   "source": [
    "di \"RSS = \" e(rss)\n",
    "di \"R^2 = \" e(r2)\n",
    "di \"df  = \" e(df_m) // df for the model (as opposed to df_r for residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to make your output more readable, you can [format the display command](https://www.stata.com/manuals13/dformat.pdf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RSS = 17,402,286   \n",
      "\n",
      "R^2 = 0.0419\n",
      "\n",
      "df  = 10\n"
     ]
    }
   ],
   "source": [
    "di \"RSS = \" %-13.0fc e(rss)\n",
    "di \"R^2 = \" %-5.4f e(r2)\n",
    "di \"df  = \" e(df_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the table, you need to store these values. You can either do that using a macro or by generating a variable. I'll go through the code first using variables, then at the end show you how to get the result using local macros and loops with a much less code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quietly {\n",
    "    gen rss1 = e(rss)\n",
    "    gen r21  = e(r2)\n",
    "    gen df1  = e(df_m)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant Characteristics\n",
    "\n",
    "There are 38 observable characteristics (the $X_i$ from the regressions), and finding them all in the codebook is a bit of a pain. I'll type the command with comments for each class of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RSS = 16,140,837   \n",
      "\n",
      "R^2 = 0.1114\n",
      "\n",
      "df  = 47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quietly reg score yyqq_*            ///\n",
    "    service*                        /// type of inspection\n",
    "    lflag_*                         /// liquor license dummies\n",
    "    f_* missfdty                    /// type of food\n",
    "    sty_* missstyl                  /// style of restaurant\n",
    "    oldchainyes                     /// chain\n",
    "    oldindown                       /// independently-owned\n",
    "    zagat*                          /// zagat survey score and dummy\n",
    "    restage misage                  /// restaurant age in years\n",
    "    risk*                           /// risk assessment dummies\n",
    "    small_rest big_rest mis_bigrest /// restaurant size dummies\n",
    "    , robust\n",
    "    \n",
    "di \"RSS = \" %-13.0fc e(rss)\n",
    "di \"R^2 = \" %-5.4f e(r2)\n",
    "di \"df  = \" e(df_m)\n",
    "\n",
    "quietly {\n",
    "    gen rss2 = e(rss)\n",
    "    gen r22  = e(r2)\n",
    "    gen df2  = e(df_m)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City Fixed Effects\n",
    "\n",
    "This time the variable is actually coded in a sensible way and is easy to find in the readme: `locctyid`. Since this is encoded, we can use factor variables to generate dummies in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RSS = 14,614,335   \n",
      "\n",
      "R^2 = 0.1954\n",
      "\n",
      "df  = 159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quietly reg score yyqq_* i.locctyid, robust\n",
    "\n",
    "di \"RSS = \" %-13.0fc e(rss)\n",
    "di \"R^2 = \" %-5.4f e(r2)\n",
    "di \"df  = \" e(df_m)\n",
    "\n",
    "quietly {\n",
    "    gen rss3 = e(rss)\n",
    "    gen r23  = e(r2)\n",
    "    gen df3  = e(df_m)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip Code Fixed Effects\n",
    "\n",
    "Again, we can find the variable that stores restaurant zip codes easily in the readme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RSS = 13,298,310   \n",
      "\n",
      "R^2 = 0.2679\n",
      "\n",
      "df  = 313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quietly reg score yyqq_* i.addrzip, robust\n",
    "\n",
    "di \"RSS = \" %-13.0fc e(rss)\n",
    "di \"R^2 = \" %-5.4f e(r2)\n",
    "di \"df  = \" e(df_m)\n",
    "\n",
    "quietly {\n",
    "    gen rss4 = e(rss)\n",
    "    gen r24  = e(r2)\n",
    "    gen df4  = e(df_m)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant Fixed Effects\n",
    "\n",
    "The restaurant identifies are recorded in `dhsid`, which is a string variable. Remember we can't put string variables into regressions, but we can [encode](https://www.stata.com/manuals13/dencode.pdf) them, which assigns a number to each unique observation and labels that value with the original string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode dhsid, gen(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the labels are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     +-------------+\n",
      "     | dhsid    id |\n",
      "     |-------------|\n",
      "  1. |     1     1 |\n",
      "  2. |     1     1 |\n",
      "  3. |     1     1 |\n",
      "  4. |     1     1 |\n",
      "  5. |    10    10 |\n",
      "     |-------------|\n",
      "  6. |    10    10 |\n",
      "  7. |    10    10 |\n",
      "  8. |    10    10 |\n",
      "  9. |    10    10 |\n",
      " 10. |   100   100 |\n",
      "     +-------------+\n"
     ]
    }
   ],
   "source": [
    "list dhsid id in 1/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now Stata knows to treat id as a numeric variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "dhsid                                                    scrambled restaurant id\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "                  type:  string (str5)\n",
      "\n",
      "         unique values:  22,202                   missing \"\":  0/83,790\n",
      "\n",
      "              examples:  \"14399\"\n",
      "                         \"18006\"\n",
      "                         \"2305\"\n",
      "                         \"4953\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "id                                                       scrambled restaurant id\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "                  type:  numeric (long)\n",
      "                 label:  id, but 1 nonmissing value is not labeled\n",
      "\n",
      "                 range:  [1,22202]                    units:  1\n",
      "         unique values:  22,202                   missing .:  0/83,790\n",
      "\n",
      "              examples:  4471  14399\n",
      "                         8190  18006\n",
      "                         13219 2305\n",
      "                         17109 4953\n"
     ]
    }
   ],
   "source": [
    "codebook dhsid id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could conceivably use factor variables to generate the dummies we need, but notice how many unique values this takes: 22,202! Remember that Stata uses matrices to run regressions, and this would create a matrix with 22,202 columns (not counting the year-quarter dummies!). Thankfully, Stata has a command to handle regressions with large numbers of dummy variables: `areg`. [See the documentation](https://www.stata.com/manuals13/rareg.pdf) for syntax and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note: yyqq_11 omitted because of collinearity\n",
      "note: yyqq_12 omitted because of collinearity\n",
      "note: yyqq_13 omitted because of collinearity\n",
      "note: yyqq_14 omitted because of collinearity\n",
      "\n",
      "Linear regression, absorbing indicators         Number of obs     =     83,790\n",
      "Absorbed variable: id                           No. of categories =     22,202\n",
      "                                                F(  10,  61578)   =     729.87\n",
      "                                                Prob > F          =     0.0000\n",
      "                                                R-squared         =     0.6242\n",
      "                                                Adj R-squared     =     0.4886\n",
      "                                                Root MSE          =    10.5290\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "       score |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "      yyqq_1 |  -9.497105   .3631232   -26.15   0.000    -10.20883   -8.785383\n",
      "      yyqq_2 |  -8.956803   .3607145   -24.83   0.000    -9.663805   -8.249802\n",
      "      yyqq_3 |  -8.675815   .3558907   -24.38   0.000    -9.373361   -7.978268\n",
      "      yyqq_4 |  -8.718674   .3564241   -24.46   0.000    -9.417266   -8.020082\n",
      "      yyqq_5 |  -8.925828   .3540719   -25.21   0.000     -9.61981   -8.231846\n",
      "      yyqq_6 |  -8.735047   .3572391   -24.45   0.000    -9.435236   -8.034857\n",
      "      yyqq_7 |  -8.501859   .3545779   -23.98   0.000    -9.196832   -7.806885\n",
      "      yyqq_8 |  -9.067227   .3515768   -25.79   0.000    -9.756318   -8.378136\n",
      "      yyqq_9 |  -.0233702   .3602459    -0.06   0.948    -.7294531    .6827128\n",
      "     yyqq_10 |  -.2431492   .3619348    -0.67   0.502    -.9525423    .4662439\n",
      "     yyqq_11 |          0  (omitted)\n",
      "     yyqq_12 |          0  (omitted)\n",
      "     yyqq_13 |          0  (omitted)\n",
      "     yyqq_14 |          0  (omitted)\n",
      "       _cons |   83.90912   .3317779   252.91   0.000     83.25883     84.5594\n",
      "------------------------------------------------------------------------------\n",
      "F test of absorbed indicators: F(22201, 61578) = 4.297        Prob > F = 0.000\n"
     ]
    }
   ],
   "source": [
    "areg score yyqq_*, absorb(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the `e()` vector are slightly different for this command, since `e(df_m)` only returns the non-absorbed variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RSS = 6,826,503    \n",
      "\n",
      "R^2 = 0.6242\n",
      "\n",
      "dfm = 10\n",
      "\n",
      "dfa = 22201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "di \"RSS = \" %-13.0fc e(rss)\n",
    "di \"R^2 = \" %-5.4f e(r2)\n",
    "di \"dfm = \" e(df_m)\n",
    "di \"dfa = \" e(df_a)\n",
    "\n",
    "quietly {\n",
    "    gen rss5 = e(rss)\n",
    "    gen r25  = e(r2)\n",
    "    gen df5  = e(df_a)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That handles almost all of the rows, but there's one last row for the number of observations. Because that's recorded in the same column as the number of regressors, we'll generate a sixth `df` variable to capture this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "quietly gen df6 = e(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it's a good idea to save this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "file data/table2.dta saved\n"
     ]
    }
   ],
   "source": [
    "cap mkdir data\n",
    "save data/table2, replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Table\n",
    "\n",
    "Now that we have all of our data, we need to rearrange it into a table that we can print. As usual, we can use some combination of the `reshape` and `collapse` commands to acheive this.\n",
    "\n",
    "First, we collapse the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "use data/table2, clear\n",
    "collapse df* rss* r2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we reshape the data from wide to long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(note: j = 1 2 3 4 5 6)\n",
      "(note: rss6 not found)\n",
      "(note: r26 not found)\n",
      "\n",
      "Data                               wide   ->   long\n",
      "-----------------------------------------------------------------------------\n",
      "Number of obs.                        1   ->       6\n",
      "Number of variables                  17   ->       5\n",
      "j variable (6 values)                     ->   regression\n",
      "xij variables:\n",
      "                        df1 df2 ... df6   ->   df\n",
      "                     rss1 rss2 ... rss6   ->   rss\n",
      "                        r21 r22 ... r26   ->   r2\n",
      "-----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen i = _n\n",
    "reshape long df rss r2, i(i) j(regression)\n",
    "drop i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all of the data we need in the table format we need it in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     +----------------------------------------+\n",
      "     | regres~n      df        rss         r2 |\n",
      "     |----------------------------------------|\n",
      "  1. |        1      10   1.74e+07   .0419108 |\n",
      "  2. |        2      47   1.61e+07   .1113604 |\n",
      "  3. |        3     159   1.46e+07   .1954025 |\n",
      "  4. |        4     313   1.33e+07   .2678567 |\n",
      "  5. |        5   22201    6826503   .6241644 |\n",
      "     |----------------------------------------|\n",
      "  6. |        6   83790          .          . |\n",
      "     +----------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to format this to make it more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     +-----------------------------------------------------------+\n",
      "     |                 regression       df          rss       r2 |\n",
      "     |-----------------------------------------------------------|\n",
      "  1. |                   Constant       10   17,402,286   0.0419 |\n",
      "  2. | Restaurant Characteristics       47   16,140,837   0.1114 |\n",
      "  3. |         City Fixed Effects      159   14,614,335   0.1954 |\n",
      "  4. |     Zip Code Fixed Effects      313   13,298,310   0.2679 |\n",
      "  5. |   Restaurant Fixed Effects   22,201    6,826,503   0.6242 |\n",
      "  6. |               Observations   83,790            .        . |\n",
      "     +-----------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "* Format data for display\n",
    "format df  %15.0fc\n",
    "format rss %15.0fc\n",
    "format r2  %15.4f\n",
    "\n",
    "* Label values of regression variable\n",
    "lab def reglab ///\n",
    "    1 \"Constant\" ///\n",
    "    2 \"Restaurant Characteristics\" ///\n",
    "    3 \"City Fixed Effects\" ///\n",
    "    4 \"Zip Code Fixed Effects\" ///\n",
    "    5 \"Restaurant Fixed Effects\" ///\n",
    "    6 \"Observations\"\n",
    "lab val regression reglab\n",
    "lab var regression \"Specification\"\n",
    "\n",
    "* List with no separators\n",
    "list, sep(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concise Method\n",
    "\n",
    "Now that you know how the code works, I'm going to try cleaning it up a bit using macros and loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "use data/q6, clear\n",
    "encode dhsid, gen(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I want to create macros for the dependent variables in each regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "local X1 \"\"\n",
    "local X2 \"service* lflag_* f_* sty_* missfdty missstyl oldchainyes oldindown zagatyes zagatfood restage misage risk* small_rest big_rest mis_bigrest\"\n",
    "local X3 \"i.locctyid\"\n",
    "local X4 \"i.addrzip\"\n",
    "local X5 \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I want to loop through rows of the table and save the data I need in macros. I can do this with a `forval` loop, but I need to include some special code to handle the case where we use the `areg` command instead of `reg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "forval i = 1/5 {\n",
    "    * Use `areg` for row 5, `reg` otherwise\n",
    "    local cmd = cond(`i'==5, \"areg\", \"reg\")\n",
    "    local abs = cond(`i'==5, \"absorb(id)\", \"\")\n",
    "    \n",
    "    * Run the regression\n",
    "    quietly `cmd' score yyqq_* `X`i'', `abs' robust\n",
    "    \n",
    "    * Store output in macros\n",
    "    local rss_`i' = e(rss)\n",
    "    local r2_`i'  = e(r2)\n",
    "    local df_`i'  = cond(`i'==5, e(df_a), e(df_m)) // use e(df_a) for `areg`\n",
    "}\n",
    "local df_6 = e(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can just type out the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            Number of  Sum of squared\n",
      "                            variables    residuals        R^2\n",
      "--------------------------------------------------------------\n",
      "Constant                          10     17,402,286     0.0419\n",
      "Restaurant Characteristics        47     16,140,837     0.1114\n",
      "City Fixed Effects               159     14,614,335     0.1954\n",
      "Zip Code Fixed Effects           313     13,298,310     0.2679\n",
      "Restaurant Fixed Effects      22,201      6,826,503     0.6242\n",
      "Observations                  83,790\n"
     ]
    }
   ],
   "source": [
    "quietly {\n",
    "n di \"                            Number of  Sum of squared\"\n",
    "n di \"                            variables    residuals        R^2\"\n",
    "n di _dup(62) \"-\"\n",
    "n di \"Constant                    \" %8.0fc `df_1' \"  \" %13.0fc `rss_1' \"     \" %6.4f `r2_1'\n",
    "n di \"Restaurant Characteristics  \" %8.0fc `df_2' \"  \" %13.0fc `rss_2' \"     \" %6.4f `r2_2'\n",
    "n di \"City Fixed Effects          \" %8.0fc `df_3' \"  \" %13.0fc `rss_3' \"     \" %6.4f `r2_3'\n",
    "n di \"Zip Code Fixed Effects      \" %8.0fc `df_4' \"  \" %13.0fc `rss_4' \"     \" %6.4f `r2_4'\n",
    "n di \"Restaurant Fixed Effects    \" %8.0fc `df_5' \"  \" %13.0fc `rss_5' \"     \" %6.4f `r2_5'\n",
    "n di \"Observations                \" %8.0fc `df_6'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously the code is not very clean, but the output looks nice.\n",
    "\n",
    "For further study, you can download all of the code used for the paper on the [AEA website](https://www.openicpsr.org/openicpsr/project/114314/version/V1/view)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stata",
   "language": "stata",
   "name": "stata"
  },
  "language_info": {
   "codemirror_mode": "stata",
   "file_extension": ".do",
   "mimetype": "text/x-stata",
   "name": "stata",
   "version": "15.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
